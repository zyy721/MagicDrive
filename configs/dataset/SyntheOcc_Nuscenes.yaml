# @package _global_
# defaults:
#   - /dataset/Nuscenes_cache


# defaults:
#   - /dataset/Nuscenes

dataset:

  # dataset_type: NuScenesDatasetM
  dataset_type: SyntheOccNuScenesDatasetM

  dataset_root: data/nuscenes/
  dataset_process_root: data/nuscenes_mmdet3d_2/  # with visibility
  # dataset_cache_file_tag: null
  # dataset_cache_file:
  #   - null  # for train_pipeline
  #   - null  # for test_pipeline

  template: A driving scene image at {location}. {description}.

  # point_cloud_range: [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]
  # voxel_size: [0.1, 0.1, 0.2]
  # image_size: [256, 704]  # size of devfusion
  image_size: [224, 400]
  map_bound:
    x: [-50.0, 50.0, 0.5]
    y: [-50.0, 50.0, 0.5]

  view_order:
    - "CAM_FRONT_LEFT"
    - "CAM_FRONT"
    - "CAM_FRONT_RIGHT"
    - "CAM_BACK_RIGHT"
    - "CAM_BACK"
    - "CAM_BACK_LEFT"

  neighboring_view_pair:
    0: [5, 1]
    1: [0, 2]
    2: [1, 3]
    3: [2, 4]
    4: [3, 5]
    5: [4, 0]

  back_resize: [896, 1600]  # (h, w)
  back_pad: [0, 4, 0, 0]  # left, top, right and bottom

  augment2d:
    resize: [[0.25, 0.25]]
    rotate: null

  aux_data:  # order is fix (v, c_offset, c_ohw, h), here only existence
    - visibility  # 1
    - center_offset  # 2
    - center_ohw  # 4 = 2 + 2
    - height  # height of 3d bbox
  # augment2d:
  #   resize: [[0.38, 0.55], [0.48, 0.48]]  # [train, test]
  #   rotate: [-5.4, 5.4]
  #   gridmask:
  #     prob: 0.0
  #     fixed_prob: true

  augment3d:
    scale: [1.0, 1.0]  # adjust the scale
    rotate: [0.0, 0.0]  # rotation the lidar
    translate: 0  # shift
    flip_ratio: 0.0
    flip_direction: null

  # class name conversion is done through pre-process
  # re-order according to this list is done in NuScenesDataset.get_ann_info
  object_classes:
    - car
    - truck
    - construction_vehicle
    - bus
    - trailer
    - barrier
    - motorcycle
    - bicycle
    - pedestrian
    - traffic_cone

  map_classes:
    - drivable_area
    # - drivable_area*
    - ped_crossing
    - walkway
    - stop_line
    - carpark_area
    - road_divider
    - lane_divider
    # - divider
    - road_block

  input_modality:
    use_lidar: false
    use_camera: true
    use_radar: false
    use_map: false
    use_external: false

    cam_sweep_num: 1



  # bevdet data config

  # bevdet_data_config:
  #     cams: [
  #         'CAM_FRONT_LEFT', 'CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_BACK_LEFT',
  #         'CAM_BACK', 'CAM_BACK_RIGHT'
  #     ]
  #     Ncams: 6
  #     input_size: [256, 704]
  #     src_size: [900, 1600]

  #     # Augmentation
  #     resize: [0.0, 0.0]
  #     rot: [0.0, 0.0]
  #     flip: False
  #     crop_h: [0.0, 0.0]
  #     resize_test: 0.00

  # bda_aug_conf:
  #   dict(
  #     rot_lim=(0.0, 0.0),
  #     scale_lim=(0.0, 0.0),
  #     flip_dx_ratio=0.0,
  #     flip_dy_ratio=0.0)


  file_client_args:
    backend: "disk"



# this config only remove object items on map construction
# map size: (8, 200, 200)


# dataset:
  dataset_cache_file_tag: 26x200x200_map_aux_full
  dataset_cache_file:
    - ${dataset.dataset_process_root}../nuscenes_map_aux/train_${dataset.dataset_cache_file_tag}.h5
    - ${dataset.dataset_process_root}../nuscenes_map_aux/val_${dataset.dataset_cache_file_tag}.h5


  train_pipeline:
    # -
    #   type: PrepareImageInputs
    #   is_train: true
    #   data_config: ${...bevdet_data_config}

    # -
    #   type: BEVAug
    #   bda_aug_conf: ${...bda_aug_conf}
    #   classes: ${...object_classes}


    -
      type: LoadMultiViewMultiSweepImageFromFiles
      sweep_num: 1
      to_float32: True
      file_client_args: ${...file_client_args}

    -
      type: NormalizeMultiviewImage
      mean: [123.675, 116.28, 103.53]
      std: [58.395, 57.12, 57.375]
      to_rgb: True
      

    -
      type: PadMultiViewImage
      size_divisor: 32




    -
      type: LoadMultiViewImageFromFiles
      to_float32: true
    -
      type: LoadAnnotations3D
      with_bbox_3d: true
      with_label_3d: true
      with_attr_label: False
    -
      type: ImageAug3D  # random crop and rotate image and generate extrinsics
      final_dim: ${...image_size}
      resize_lim: ${...augment2d.resize[0]}  # range for resize ratio
      bot_pct_lim: [0.0, 0.0]  # this is the ratio in [0, 1] to keep bottom, default only crop top
      rot_lim: ${...augment2d.rotate}
      rand_flip: false
      is_train: false  # is false, range takes mean, disable flip and rotate
    -
      type: GlobalRotScaleTrans
      resize_lim: ${...augment3d.scale}
      rot_lim: ${...augment3d.rotate}
      trans_lim: ${...augment3d.translate}
      is_train: true
    -
      type: ObjectNameFilterM  # this removes -1, do not really filter by names
      classes: ${...object_classes}
    -
      type: LoadBEVSegmentationM
      dataset_root: ${...dataset_root}
      xbound: ${...map_bound.x}
      ybound: ${...map_bound.y}
      classes: ${...map_classes}
      object_classes: null
      aux_data: null
      cache_file: ${...dataset_cache_file.0}
    - 
      type: RandomFlip3DwithViews
      flip_ratio: ${...augment3d.flip_ratio}
      direction: ${...augment3d.flip_direction}
    # -
    #   type: RandomFlip3D  # random flip the whole lidar space
    # -
    #   type: PointsRangeFilter
    #   point_cloud_range: ${point_cloud_range}
    # -
    #   type: ObjectRangeFilter
    #   point_cloud_range: ${point_cloud_range}
    - 
      type: ReorderMultiViewImagesM
      order: ${...view_order}
      safe: False
    -
      type: ImageNormalize
      mean: [0.5, 0.5, 0.5]
      std: [0.5, 0.5, 0.5]
    -
      type: DefaultFormatBundle3D
      classes: ${...object_classes}
    -
      # type: Collect3D
      type: SyntheOccCollect3D

      keys:  # keep as origin
        - img
        # - points
        - gt_bboxes_3d
        - gt_labels_3d
        - gt_masks_bev
      meta_keys:  # send to DataContainer
        - camera_intrinsics
        - lidar2ego
        - lidar2camera
        - camera2lidar
        - lidar2image
        - img_aug_matrix
        # - lidar_aug_matrix  # this is useful when we change lidar and box
      meta_lis_keys:  # hold by one DataContainer
        - timeofday
        - location
        - description
        - filename
        - token

  test_pipeline:

    -
      type: LoadMultiViewMultiSweepImageFromFiles
      sweep_num: 1
      to_float32: True
      file_client_args: ${...file_client_args}

    -
      type: NormalizeMultiviewImage
      mean: [123.675, 116.28, 103.53]
      std: [58.395, 57.12, 57.375]
      to_rgb: True
      

    -
      type: PadMultiViewImage
      size_divisor: 32


    -
      type: LoadMultiViewImageFromFiles
      to_float32: true
    -
      type: LoadAnnotations3D
      with_bbox_3d: true
      with_label_3d: true
      with_attr_label: False
    -
      type: ImageAug3D  # keep this to perform image resize
      final_dim: ${...image_size}
      resize_lim: ${...augment2d.resize[0]}
      bot_pct_lim: [0.0, 0.0]
      rot_lim: [0.0, 0.0]
      rand_flip: false
      is_train: false
    -
      type: GlobalRotScaleTrans  # add `lidar_aug_matrix`
      resize_lim: ${...augment3d.scale}
      rot_lim: ${...augment3d.rotate}
      trans_lim: ${...augment3d.translate}
      is_train: true
    -
      type: ObjectNameFilterM
      classes: ${...object_classes}
    -
      type: LoadBEVSegmentationM
      dataset_root: ${...dataset_root}
      xbound: ${...map_bound.x}
      ybound: ${...map_bound.y}
      classes: ${...map_classes}
      object_classes: null
      aux_data: null
      cache_file: ${...dataset_cache_file.1}
    # -
    #   type: PointsRangeFilter
    #   point_cloud_range: ${point_cloud_range}
    - 
      type: ReorderMultiViewImagesM
      order: ${...view_order}
      safe: False
    -
      type: ImageNormalize
      mean: [0.5, 0.5, 0.5]
      std: [0.5, 0.5, 0.5]
    -
      type: DefaultFormatBundle3D
      classes: ${...object_classes}
    -
      type: Collect3D
      keys:
        - img
        # - points
        - gt_bboxes_3d
        - gt_labels_3d
        - gt_masks_bev
      meta_keys:
        - camera_intrinsics
        - lidar2ego
        - lidar2camera
        - camera2lidar
        - lidar2image
        - img_aug_matrix
        # - lidar_aug_matrix
      meta_lis_keys:
        - timeofday
        - location
        - description
        - filename
        - token

  data:
    # samples_per_gpu: 4  # we do not set these here.
    # workers_per_gpu: 4
    train:  # here we drop the wrapper of CBGSDataset
      type: ${...dataset_type}
      dataset_root: ${...dataset_root}
      # ann_file: ${...dataset_process_root}nuscenes_infos_train.pkl
      # ann_file: ${...dataset_process_root}magicdrive_w_bevdet_train.pkl
      # ann_file: ${...dataset_process_root}magicdrive_w_unipad_train.pkl
      ann_file: ${...dataset_process_root}magicdrive_w_unipad_syntheocc_train.pkl

      pipeline: ${...train_pipeline}
      object_classes: ${...object_classes}
      map_classes: ${...map_classes}
      modality: ${...input_modality}
      test_mode: false
      # use_valid_flag: true  # this will filter some objects, not sure why
      force_all_boxes: true  # !! even without `use_valid_flag`, objects with no lidar pts will be filtered
      box_type_3d: LiDAR  # this is ok, all boxes are under the lidar coord
      filter_empty_gt: false  # important, prevent from filter
    val:
      type: ${...dataset_type}
      dataset_root: ${...dataset_root}
      # ann_file: ${...dataset_process_root}nuscenes_infos_val.pkl
      # ann_file: ${...dataset_process_root}magicdrive_w_unipad_val.pkl
      ann_file: ${...dataset_process_root}magicdrive_w_unipad_syntheocc_val.pkl

      pipeline: ${...test_pipeline}
      object_classes: ${...object_classes}
      map_classes: ${...map_classes}
      modality: ${...input_modality}
      test_mode: false
      force_all_boxes: true  # !! even without `use_valid_flag`, objects with no lidar pts will be filtered
      box_type_3d: LiDAR
      filter_empty_gt: false  # important, prevent from filter
    test:
      type: ${...dataset_type}
      dataset_root: ${...dataset_root}
      ann_file: ${...dataset_process_root}nuscenes_infos_val.pkl
      pipeline: ${...test_pipeline}
      object_classes: ${...object_classes}
      map_classes: ${...map_classes}
      modality: ${...input_modality}
      test_mode: true
      force_all_boxes: true  # !! even without `use_valid_flag`, objects with no lidar pts will be filtered
      box_type_3d: LiDAR
      filter_empty_gt: false  # important, prevent from filter